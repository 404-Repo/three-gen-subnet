{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# THREE GEN | SUBNET 17\nTo demonstrate how SN17 works you need to look at it both from the miner and validator perspective.\n\n## Miner\n\nPrerequisites:\n- create wallet,\n- register on SN17,\n- setup a node,\n- install git, conda, pm2.\n  \nSetup:\n- git clone https://github.com/404-Repo/three-gen-subnet.git\n- cd three-gen-subnet/generation\n- ./setup_env.sh\n- pm2 start generation.config.js\n- cd ../neurons\n- ./setup_env.sh\n- pm2 start miner.config.js\n\nThis setup will run a generation endpoint locally (responsible for generating 3d assets) and bittensor neuron (responsible for communication within the subnet).\n\n## Miner pseudo-code\n\nMiner fetches tasks from validators (round robin), generate assets and submit results.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install bittensor",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import bittensor as bt\nfrom common.protocol import PullTask, SubmitResults\n\nwallet = bt.wallet(name=\"default\", hotkey=\"default\")  # validator neuron can be used as well\nsubtensor = bt.subtensor(network=\"finney\")\nmetagraph = bt.metagraph(netuid=17, network=subtensor.network, sync=True)                         \ndendrite = bt.dendrite(wallet)\n\n# Pulling the task from validator\n\nvalidator_uid = 0  # validator operated by the subnet owner\nsynapse = PullTask()\nresponse = await dendrite.call(\n            target_axon=metagraph.axons[validator_uid], synapse=synapse, deserialize=False, timeout=12.0\n        )\ntask = response.task\n\n# Generating assets\n\nasync with aiohttp.ClientSession(timeout=client_timeout) as session:\n    async with session.post(\"http://127.0.0.1:8094/generate\", data={\"prompt\": task.prompt}) as response:\n        assets = await response.text()\n\n# Signing results (needed to verify the results origin when fetching from storage subnet)\n\nsubmit_time = time.time_ns()\nmessage = f\"{submit_time}{task.prompt}{metagraph.hotkeys[validator_uid]}{wallet.hotkey.ss58_address}\"\nsignature = base64.b64encode(dendrite.keypair.sign(message)).decode(encoding=\"utf-8\")\n\n# Submitting results\n\nsynapse = SubmitResults(task=task, results=assets, submit_time=submit_time, signature=signature)\nresponse = await dendrite.call(\n    target_axon=metagraph.axons[validator_uid],\n    synapse=synapse,\n    deserialize=False,\n    timeout=300.0,\n)\n\n# Printing feedback\n\nbt.logging.debug(f\"Feedback received. Prompt: {response.task.prompt}. Score: {response.feedback.task_fidelity_score}\")\nbt.logging.debug(\n    f\"Average score: {response.feedback.average_fidelity_score}. \"\n    f\"Accepted results (last 8h): {response.feedback.generations_within_8_hours}. \"\n    f\"Reward: {response.feedback.current_miner_reward}.\"\n)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This will print:\n\n> Feedback received. Prompt: iridescent ice cube tray. Score: 1.0\n\n> Average score: 0.8543000416514985. Accepted results (last 8h): 39. Reward: 33.31770162440844.\n\nMeaning that results for the task with the prompt `iridescent ice cube tray` have been accepted. The fidelity score for the current generation is 1.0.\nEMA of the all fidelity scores is 0.85 and total number of accepted results with the score >0.75 during the last 8 hours is 39. Total miner reward is 33.32 (fidelity score * number of accepted results). Normalized miner reward is used as a weight.\n\nThere three possible outcomes for the fidelity score.\n- 1.0 - CLIP distance between a prompt and renders is >= 0.8.\n- 0.75 - CLIP distance between a prompt and renders is >= 0.6 and < 0.8.\n- 0 - CLIP distance between a prompt and renders is < 0.6.\n\nResults with fidelity score 0 are not accepted and have no effect on average fidelity score.\n\nIn the future, with the advance of the AI models, 0.6 and 0.8 threshold will be increased.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Validator\n\nPrerequisites:\n- create wallet,\n- register on SN17,\n- setup a node,\n- install git, conda, pm2.\n  \nSetup:\n- git clone https://github.com/404-Repo/three-gen-subnet.git\n- cd three-gen-subnet/validation\n- ./setup_env.sh\n- pm2 start validatoin.config.js\n- cd ../neurons\n- ./setup_env.sh\n- pm2 start validator.config.js\n\nThis setup will run validation endpoint locally (responsible for scoring generated 3d assets) and bittensor neuron (responsible for communication within the subnet).\n\n## Validator pseudo-code\n\nValidators receive organic request via public API or use synthetic task dataset if no organic request registered. Submitted results are evaluated and an 8-hours window of submitted results is tracked.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import bittensor as bt\nfrom common.protocol import PullTask, SubmitResults\n\nwallet = bt.wallet(name=\"default\", hotkey=\"default\")\nsubtensor = bt.subtensor(network=\"finney\")\nmetagraph = bt.metagraph(netuid=17, network=subtensor.network, sync=True)                         \n\naxon = bt.axon(wallet=wallet, config=self.config)\nself.axon.attach(\n    forward_fn=pull_task\n).attach(\n    forward_fn=submit_results\n)\n\ndef pull_task(synapse: PullTask) -> PullTask:\n    organic_task = self.task_registry.get_next_task(synapse.dendrite.hotkey)\n    if organic_task is not None:\n        task = Task(id=organic_task.id, prompt=organic_task.prompt)\n    else:\n        task = Task(prompt=self.dataset.get_random_prompt())\n\n    synapse.task = task\n    synapse.submit_before = int(time.time()) + self.config.generation.task_timeout\n    synapse.version = NEURONS_VERSION\n    return synapse\n\nasync def submit_results(synapse: SubmitResults) -> SubmitResults:\n    uid = get_neuron_uid(synapse.dendrite.hotkey)\n    miner = miners[uid]\n    \n    if not verify_results_signature(synapse):\n        return add_feedback(synapse, miner)\n\n    async with aiohttp.ClientSession() as session:\n        async with session.post(\"http://127.0.0.1:8093\", json={\"prompt\": synapse.task.prompts, \"data\": synapse.results}) as response:\n            results = await response.json()\n            validation_score = float(results[\"score\"])\n\n    if validation_score >= 0.8:\n        fidelity_score = 1\n    elif validation_score >= 0.6:\n        fidelity_score = 0.75\n    else:\n        fidelity_score = 0\n\n    if fidelity_score == 0:\n        return add_feedback(synapse, miner)\n\n    storage.store(synapse)  # storing to SN21\n\n    miner.add_observation(fidelity_score)\n\n    task_registry.complete_task(synapse.task.id, synapse.dendrite.hotkey, synapse.results, validation_score)\n\n    return add_feedback(synapse, miner, fidelity_score=fidelity_score)\n\ndef add_feedback(\n    synapse: SubmitResults,\n    miner: MinerData,\n    fidelity_score: float = 0.0,\n    current_time: int | None = None,\n) -> SubmitResults:\n    if current_time is None:\n        current_time = int(time.time())\n    reward = miner.fidelity_score * len(miner.observations)\n    synapse.feedback = Feedback(\n        task_fidelity_score=fidelity_score,\n        average_fidelity_score=miner.fidelity_score,\n        generations_within_8_hours=len(miner.observations),\n        current_miner_reward=reward,\n    )\n    synapse.cooldown_until = current_time + self.config.generation.task_cooldown\n    return synapse",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Miner incentive\nThere is a clear path on how to increase the incentive.\n- Running higher tier GPU or using multiple generation endpoints to submit more results, will increase the miner reward.\n- Train or replace the 3D model to generate acceptable results for all prompts.\n- Train or replace the 3D model to generate results with higher fidelity score.\n\nWith the advance of 3D generation models, quality criteria for generated images will be increased.  ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Validation algorithm",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom transformers import CLIPProcessor, CLIPModel\n\ndef render_images(miner_result: str) -> list[np.ndarray]:\n    \"\"\" Function for rendering multiple view of the input geometry\n    Args:\n        miner_result: encoded buffer with data that contains generated geometry provided by the miner\n    Returns: a list with rendered images\n    \"\"\"\n    geometry = unpack(miner_result)\n    orbitcam = OrbitCamera()\n    images = []\n    for azimuth_angle in range(0, 360, 10):\n        # min_ver = -20, max_ver = 20 degrees\n        elevation_angle = np.random.randint(min_ver, max_ver)\n        # get orbit camera transformation matrix 4x4 = [R | T]\n        pose = orbit_camera(angle)\n        camera = BasicCamera(pose)\n        image = renderer.render(camera, geometry)\n        images.append(image)\n    return images\n\n\ndef score(prompt: str, images: list[np.ndarray]) -> float\n    \"\"\" Function for scoring the the result of miner's work using CLIP model\n    Args:\n        prompt: string with input prompt that was used for generating the input geometry\n        images: a list with rendered images of the input geometry\n    Returns: a single score between 0 and 1 that identifies how far the generated geometry from the \n             used prompt for its generation. \n    \"\"\"\n    # preloading CLIP model\n    model = CLIPModel.from_pretrained(scoring_model)\n    processor = CLIPProcessor.from_pretrained(scoring_model)\n\n    # add prompts (always false) against which input prompt\n    # will be compared\n    negative_prompts = [\n            \"empty\",\n            \"nothing\",\n            \"false\",\n            \"wrong\",\n            \"negative\",\n            \"not quite right\",\n        ]\n    negative_prompts.append(prompt)\n\n    scores = []\n    for img in images:\n        inputs = processor(prompts, img)\n        results = model(**inputs)\n        # we take the score for the last prompt in negative prompts\n        # that will be input prompt\n        score = logits_per_image.softmax(dim=1)[0][-1]\n        scores.append(score)\n        \n    return np.mean(scores)\n\n\ndef validate(prompt: str, miner_result: str):\n    \"\"\" Function for computing the validation score\n    Args:\n        prompt string with input prompt that was used for generating the input geometry\n        miner_result: encoded buffer with data that contains generated geometry provided by the miner\n    Returns: a float value (validation score) between 0 and 1\n    \"\"\"\n    images = render_images(miner_result)\n    validation_score = score(prompt, miner_result)\n    return validation_score ",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Dataset \n\nThe existing datasets from Hugging Face do not adequately meet the requirements of state-of-the-art 3D generators. A more streamlined dataset is essential for optimal performance. We have established a continuous dataset generation process to ensure the following criteria are met:\n- It is feasible to generate 3D assets from the provided prompts.\n- Generated assets can be validated effectively.\n- There are no duplicates within the dataset.\n- We are able to generate new prompts more rapidly than miners can pre-generate existing ones.\n\nYou can find our code for dataset generation at this GitHub repository: https://github.com/404-Repo/text-prompt-generator\n\nThe dataset generation process includes the following steps:\n- Generating prompts using Llama.\n- Filtering the initially generated prompts.\n- Running a validation on the filtered prompts.\n- Collecting statistics on the proportion of accepted versus failed generations.\n- Adjusting the filtering criteria based on the observed outcomes.\nThis method ensures continuous improvement and relevance of the dataset to the needs of advanced 3D generation technologies.\n\nCurrently used prompts: https://github.com/404-Repo/three-gen-subnet/blob/main/resources/prompts.txt\n\nIn addition to our existing framework, we are currently developing a new generation pipeline that introduces an intermediate step of converting text to images. This approach allows us to apply various styling filters to each image, significantly expanding our dataset. Each image will be transformed through multiple stylistic variations, effectively multiplying the size of the dataset by the number of different styles available.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Subnet API\n\nValidators can optionally expose the API and allow subnet clients to query the subnet and request 3D assets generation. This is done by simply passing the configuration parameter: `--public_api.enabled`.\n\n## Subnet Client Code",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import bittensor as bt\nfrom api import Generate, StatusCheck, TaskStatus\n\nwallet = bt.wallet(name=\"default\", hotkey=\"default\")\nsubtensor = bt.subtensor(network=\"finney\")\nmetagraph = bt.metagraph(netuid=17, network=subtensor.network, sync=True)\ndendrite = bt.dendrite(wallet)\n\nvalidator_uid = 0  # validator operated by the subnet owner\nsynapse = Generate(prompt=\"Bill Gates\")\nresponse = await dendrite.call(target_axon=metagraph.axons[validator_uid], synapse=synapse, deserialize=False, timeout=12.0)\n\nwhile True:\n    await asyncio.sleep(10.0)\n    synapse = StatusCheck(task_id=task_id)\n    response = await dendrite.call(target_axon=metagraph.axons[validator_uid], synapse=synapse, deserialize=False, timeout=300.0)\n    if response.status == TaskStatus.DONE:\n        break\n\nbt.logging.info(f\"Results: {len(response.results)}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}